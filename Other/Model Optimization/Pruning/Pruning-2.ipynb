{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data is ok\n"
     ]
    }
   ],
   "source": [
    "#加载数据集合\n",
    "#加载MNIST数据集\n",
    "(train_images, train_labels), (test_images, test_labels) = keras.datasets.mnist.load_data()\n",
    "#将图像像素值规整到[0,1]\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "print(\"load data is ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([ keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "                           keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "                           keras.layers.Conv2D(filters=12,kernel_size=(3, 3), activation='relu'),\n",
    "                           keras.layers.MaxPooling2D(pool_size=(2,2)),\n",
    "                           keras.layers.Flatten(),\n",
    "                           keras.layers.Dense(10)])\n",
    "model.compile(optimizer = 'adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/4\n",
      "54000/54000 [==============================] - 6s 116us/sample - loss: 0.3169 - accuracy: 0.9100 - val_loss: 0.1354 - val_accuracy: 0.9643\n",
      "Epoch 2/4\n",
      "54000/54000 [==============================] - 6s 108us/sample - loss: 0.1278 - accuracy: 0.9637 - val_loss: 0.0879 - val_accuracy: 0.9787\n",
      "Epoch 3/4\n",
      "54000/54000 [==============================] - 6s 110us/sample - loss: 0.0885 - accuracy: 0.9747 - val_loss: 0.0738 - val_accuracy: 0.9803\n",
      "Epoch 4/4\n",
      "54000/54000 [==============================] - 6s 117us/sample - loss: 0.0714 - accuracy: 0.9791 - val_loss: 0.0666 - val_accuracy: 0.9832\n",
      "Saved pruned Keras model to: D:\\riky\\jupyterpro\\Tensorflow\\tmp35qq2zf9.h5\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_images,train_labels,epochs = 4,validation_split = 0.1)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5',dir='./')\n",
    "tf.keras.models.save_model(model, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对整个模型进行剪枝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 11:03:58.645002 10648 hdf5_format.py:177] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "******************************************************************\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape_ (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 26, 26, 12)        230       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten_ (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 10)                40572     \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#加载原来已经训练好的模型\n",
    "base_model = keras.models.load_model('tmp35qq2zf9.h5')\n",
    "base_model.summary()\n",
    "print(\"******************************************************************\")\n",
    "\n",
    "#如果对整个模型进行剪枝，可以查看改模型的情况, 可以看到模型输出的名称都不一样\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修剪模型的某一部分(最好模型剪枝之前已经加载了权值)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer name: reshape_1\n",
      "layer name: conv2d_1\n",
      "layer name: max_pooling2d_1\n",
      "layer name: flatten_1\n",
      "layer name: dense_1\n",
      "Apply pruning to Dense\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 10)                40572     \n",
      "=================================================================\n",
      "Total params: 40,692\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,282\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#修剪模型的Dense Layer   ,可以通过网络的名字来进行确定剪枝层\n",
    "def apply_pruning_to_dense(layer):\n",
    "    print(\"layer name:\",layer.name)\n",
    "    if isinstance(layer,tf.keras.layers.Dense):\n",
    "        print(\"Apply pruning to Dense\")\n",
    "        return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "    return layer\n",
    "#其中tf.keras.models.clone_model是对keras定义的层进行一些改变，具体看一看 官方api\n",
    "model_for_pruning = tf.keras.models.clone_model(base_model,clone_function= apply_pruning_to_dense)\n",
    "model_for_pruning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape_1\n"
     ]
    }
   ],
   "source": [
    "print(base_model.layers[0].name)  #查看模型某一层的名字"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义剪枝操作，通过 tfmot.sparsity.keras.PrunableLayer 自定需要剪枝的参数，常有两种情况：（通常bia的prune会严重降低精度，默认是不会prune的，此处只作示例）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0909 11:54:45.299134 10648 hdf5_format.py:177] No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\riky\\AppData\\Local\\Temp\\tmp_2xm4k78\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "prune_low_magnitude_reshape_ (None, 28, 28, 1)         1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_conv2d_1 (None, 26, 26, 12)        230       \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_max_pool (None, 13, 13, 12)        1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_flatten_ (None, 2028)              1         \n",
      "_________________________________________________________________\n",
      "prune_low_magnitude_dense_1  (None, 10)                40572     \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 16s 264us/sample - loss: 0.0655 - accuracy: 0.9812\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 14s 241us/sample - loss: 0.0562 - accuracy: 0.9836\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 0.0519 - accuracy: 0.9847\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 15s 248us/sample - loss: 0.0480 - accuracy: 0.9859\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 15s 243us/sample - loss: 0.0449 - accuracy: 0.9866\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 14s 232us/sample - loss: 0.0425 - accuracy: 0.9875\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 14s 230us/sample - loss: 0.0403 - accuracy: 0.9886\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 14s 236us/sample - loss: 0.0381 - accuracy: 0.9890\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 15s 242us/sample - loss: 0.0368 - accuracy: 0.9894\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 14s 233us/sample - loss: 0.0352 - accuracy: 0.9897\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 13s 222us/sample - loss: 0.0337 - accuracy: 0.9902\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.0323 - accuracy: 0.9905\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.0312 - accuracy: 0.9909\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 13s 224us/sample - loss: 0.0299 - accuracy: 0.9912\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 13s 223us/sample - loss: 0.0287 - accuracy: 0.9912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d550ad79c8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = keras.models.load_model('tmp35qq2zf9.h5')\n",
    "# base_model.summary()\n",
    "\n",
    "# #PolynomialDecay方法定义一个具有多项式衰减功能的修剪计划，也就是说修剪过程中的稀疏度是变化的，网络参数逐渐减少，稀疏度逐渐提高。\n",
    "# pruning_schedule = tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "#                                                         final_sparsity=0.80,\n",
    "#                                                         begin_step=0,\n",
    "#                                                         end_step=end_step)\n",
    "# #修改要在训练期间修剪的tf.keras层或模型，本例修剪的是整个模型的参数\n",
    "# model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(model, pruning_schedule)\n",
    "\n",
    "log_dir = tempfile.mkdtemp()\n",
    "print(log_dir)#查看保存地址\n",
    "\n",
    "model_for_pruning = tfmot.sparsity.keras.prune_low_magnitude(base_model)\n",
    "model_for_pruning.summary()\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),  #回调函数，使其在训练过程中处理修减更新\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=log_dir), #提供用于跟踪进度和调试的日志\n",
    "]\n",
    "\n",
    "\n",
    "model_for_pruning.compile(loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True),\n",
    "                          optimizer = \"adam\",\n",
    "                          metrics = [\"accuracy\"])\n",
    "model_for_pruning.fit(train_images, train_labels, callbacks = callbacks, epochs = 15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't assign to operator (<ipython-input-35-5341426ab8ac>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-35-5341426ab8ac>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    tensorboard --logdir=log_dir\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to operator\n"
     ]
    }
   ],
   "source": [
    "tensorboard --logdir=log_dir  #就是使用tensorboard 打开改文件夹，要使用控制台才行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用strip_pruning去除之前的不可训练权重,并保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#获得模型权重大小 \n",
    "def get_gzipped_model_size(model):\n",
    "    import os\n",
    "    import zipfile\n",
    "    _, keras_file = tempfile.mkstemp('.h5')\n",
    "    model.save(keras_file, include_optimizer=False)\n",
    "    \n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(keras_file)\n",
    "    return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final model\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 12)        120       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 12)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2028)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20290     \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#使用strip_pruning去除之前的不可训练权重,并保存模型\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)#使用strip_pruning去除之前的不可训练权重,并保存模型\n",
    "print(\"final model\")\n",
    "model_for_export.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Size of gzipped pruned model without stripping: 49131.00 bytes\n",
      "Size of gzipped pruned model with stripping: 49131.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\")\n",
    "print(\"Size of gzipped pruned model without stripping: %.2f bytes\" % (get_gzipped_model_size(base_model)))\n",
    "print(\"Size of gzipped pruned model with stripping: %.2f bytes\" % (get_gzipped_model_size(model_for_export)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
